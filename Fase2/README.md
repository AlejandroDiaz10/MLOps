# German Credit Risk Prediction

[![Python 3.12.1](https://img.shields.io/badge/python-3.12.1-blue.svg)](https://www.python.org/downloads/)
[![scikit-learn](https://img.shields.io/badge/sklearn-1.3.0-orange.svg)](https://scikit-learn.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

Sistema de clasificaciÃ³n de riesgo crediticio implementando mejores prÃ¡cticas de MLOps: estructura Cookiecutter, programaciÃ³n orientada a objetos, sklearn Pipeline y experiment tracking.

**Equipo:** Team 34 | **Curso:** Machine Learning | **Fecha:** Octubre 2025

---

## ğŸ¯ Quickstart

```bash
# 1. Clonar e instalar
git clone https://github.com/AlejandroDiaz10/MLOps
cd Fase2
pip install -r requirements.txt && pip install -e .

# 2. Entrenar modelo
python run_pipeline.py

# 3. Comparar modelos
python run_pipeline.py compare
```

---

## ğŸ“Š Resultados

**Mejores modelos (Test Set):**

| Modelo | AUC-ROC | Accuracy | F1-Score |
|--------|---------|----------|----------|
| Random Forest | **0.8196** | 0.7464 | 0.8416 |
| Logistic Regression | 0.8186 | 0.7971 | 0.8716 |
| Decision Tree | 0.7680 | 0.7681 | 0.8431 |

**Meta alcanzada:** AUC-ROC â‰¥ 0.75 âœ…

---

## ğŸ—ï¸ ImplementaciÃ³n de Mejores PrÃ¡cticas

Este proyecto implementa las **4 etapas** de desarrollo profesional en Machine Learning:

### **Etapa 1: EstructuraciÃ³n del Proyecto**

**Objetivo:** OrganizaciÃ³n estandarizada del cÃ³digo usando Cookiecutter Data Science.

**ImplementaciÃ³n:**
```
Fase2/
â”œâ”€â”€ run_pipeline.py             # ğŸ¯ Script principal
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ pyproject.toml
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Datos originales
â”‚   â”œâ”€â”€ interim/                # Datos limpiados
â”‚   â””â”€â”€ processed/              # Train/test splits
â”‚
â”œâ”€â”€ models/                     # Modelos .pkl + metadata
â”‚
â”œâ”€â”€ reports/figures/            # Confusion matrix, ROC curves
â”‚
â”œâ”€â”€ notebooks/                  # AnÃ¡lisis exploratorio
â”‚   â”œâ”€â”€ 1.0-t34-data-exploration.ipynb
â”‚   â”œâ”€â”€ 2.0-t34-feature-engineering.ipynb
â”‚   â”œâ”€â”€ 3.0-t34-model-training.ipynb
â”‚   â””â”€â”€ 4.0-t34-sklearn-pipeline-best-practices.ipynb
â”‚
â””â”€â”€ fase2/                      # CÃ³digo fuente
    â”œâ”€â”€ config.py               # ConfiguraciÃ³n (Pydantic)
    â”œâ”€â”€ pipeline_builder.py     # sklearn Pipeline builder
    â”œâ”€â”€ plots.py                # Visualizaciones
    â”‚
    â”œâ”€â”€ core/                   # LÃ³gica de negocio (OOP)
    â”‚   â”œâ”€â”€ data_processor.py
    â”‚   â”œâ”€â”€ feature_engineer.py
    â”‚   â””â”€â”€ model_factory.py
    â”‚
    â””â”€â”€ modeling/
        â”œâ”€â”€ train.py            # Entrenamiento
        â””â”€â”€ predict.py          # EvaluaciÃ³n
```

**Beneficios:**
- âœ… SeparaciÃ³n clara entre datos raw y procesados
- âœ… CÃ³digo reproducible y versionable
- âœ… Facilita colaboraciÃ³n en equipo

---

### **Etapa 2: RefactorizaciÃ³n con OOP**

**Objetivo:** CÃ³digo mantenible, escalable y testeable mediante programaciÃ³n orientada a objetos.

**Componentes principales:**

| Clase | Responsabilidad | PatrÃ³n de DiseÃ±o |
|-------|----------------|------------------|
| `DataProcessor` | Limpieza y validaciÃ³n de datos | Method Chaining |
| `FeatureEngineer` | Feature engineering y splits | Method Chaining |
| `ModelFactory` | CreaciÃ³n de modelos ML | Factory Pattern |
| `PipelineBuilder` | ConstrucciÃ³n de pipelines | Builder Pattern |
| `ModelTrainer` | Entrenamiento y validaciÃ³n | Template Method |
| `ModelEvaluator` | EvaluaciÃ³n de modelos | - |

**Ejemplo de uso:**
```python
from fase2.core.data_processor import DataProcessor

# Method chaining para limpieza
processor = DataProcessor()
df_clean = (processor
    .load_raw_data()
    .translate_columns()
    .clean_whitespace()
    .convert_to_numeric()
    .validate_target()
    .handle_missing_values()
    .remove_duplicates()
    .get_data())
```

**Principios SOLID aplicados:**
- **Single Responsibility:** Cada clase tiene una Ãºnica responsabilidad
- **Open/Closed:** Extensible sin modificar cÃ³digo existente
- **Dependency Inversion:** ConfiguraciÃ³n inyectable

**Beneficios:**
- âœ… CÃ³digo modular y reutilizable
- âœ… FÃ¡cil mantenimiento a largo plazo
- âœ… Testing simplificado

---

### **Etapa 3: sklearn Pipeline & Best Practices**

**Objetivo:** Automatizar preprocesamiento, entrenamiento y evaluaciÃ³n de forma reproducible.

**Arquitectura del Pipeline:**
```python
sklearn.Pipeline([
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler()),
    ('model', RandomForestClassifier(random_state=42))
])
```

**Ventajas sobre cÃ³digo tradicional:**

| Sin Pipeline | Con sklearn Pipeline |
|-------------|---------------------|
| âŒ Data leakage (fit en todo el dataset) | âœ… Fit solo en train set |
| âŒ MÃºltiples objetos a serializar | âœ… Un solo .pkl |
| âŒ Preprocessing manual en producciÃ³n | âœ… Preprocessing automÃ¡tico |
| âŒ DifÃ­cil reproducir experimentos | âœ… Reproducible por diseÃ±o |

**ImplementaciÃ³n:**
```python
from fase2.pipeline_builder import PipelineBuilder

# ConstrucciÃ³n automÃ¡tica del pipeline
builder = PipelineBuilder()
grid_pipeline = builder.build_grid_search_pipeline(
    model_name='random_forest',
    cv_folds=5
)

# Entrenamiento con GridSearchCV
grid_pipeline.fit(X_train, y_train)

# SerializaciÃ³n (un solo objeto)
joblib.dump(grid_pipeline.best_estimator_, 'model.pkl')

# ProducciÃ³n (carga y predice)
model = joblib.load('model.pkl')
predictions = model.predict(X_new)  # Preprocessing incluido
```

**Best practices implementadas:**
- âœ… Cross-validation con GridSearchCV
- âœ… BÃºsqueda de hiperparÃ¡metros automÃ¡tica
- âœ… No data leakage (fit/transform separados)
- âœ… Reproducibilidad (`random_state=42`)
- âœ… Pipeline serializable completo

**Beneficios:**
- âœ… CÃ³digo listo para producciÃ³n
- âœ… ReducciÃ³n de errores humanos
- âœ… Experimentos reproducibles

---

### **Etapa 4: Experiment Tracking & Model Management** â³

**Objetivo:** Tracking sistemÃ¡tico de experimentos, versionamiento de modelos y comparaciÃ³n de resultados.

**Herramientas a implementar:**

**1. MLflow**
- [ ] Tracking de parÃ¡metros e hiperparÃ¡metros
- [ ] Logging de mÃ©tricas (AUC, accuracy, F1)
- [ ] Registro de artifacts (modelos, plots)
- [ ] Model Registry con versionamiento
- [ ] ComparaciÃ³n visual de experimentos
- [ ] TransiciÃ³n de stages (Dev â†’ Staging â†’ Production)

**2. DVC (Data Version Control)**
- [ ] Versionamiento de datasets
- [ ] Versionamiento de modelos
- [ ] Pipelines reproducibles
- [ ] Remote storage (Google Drive/S3)

**Estructura prevista:**
```bash
# MLflow tracking
mlflow ui  # Dashboard en localhost:5000

# DVC versioning
dvc init
dvc remote add -d storage gdrive://...
dvc add data/raw/german_credit_modified.csv
dvc push
```

**Beneficios esperados:**
- âœ… ComparaciÃ³n sistemÃ¡tica de experimentos
- âœ… Rollback a versiones anteriores
- âœ… AuditorÃ­a completa de modelos
- âœ… ColaboraciÃ³n eficiente en equipo

---

## âš¡ EjecuciÃ³n de Pipelines

### **Pipeline Completo (Recomendado)**

```bash
# Entrenar con Random Forest (default)
python run_pipeline.py
```

**Salida:**
```
ğŸš€ GERMAN CREDIT RISK - ML PIPELINE
======================================================================
STEP 1: DATA PREPARATION       # Limpieza y validaciÃ³n
STEP 2: FEATURE ENGINEERING    # Outliers, split, scaling
STEP 3: MODEL TRAINING         # GridSearchCV con sklearn Pipeline
STEP 4: MODEL EVALUATION       # MÃ©tricas y visualizaciones

ğŸ‰ PIPELINE COMPLETED SUCCESSFULLY!
ğŸ“Š Final Results:
  Model: random_forest
  Test AUC-ROC: 0.8196
  Test Accuracy: 0.7464
```

### **Comparar MÃºltiples Modelos**

```bash
python run_pipeline.py compare
```

**Salida:**
```
ğŸ”¬ COMPARING 3 MODELS
======================================================================

Model                     AUC-ROC    Accuracy   F1-Score  
--------------------------------------------------------------
Random Forest             0.8196     0.7464     0.8416    
Logistic Regression       0.8186     0.7971     0.8716    
Decision Tree             0.7680     0.7681     0.8431    

ğŸ† Best model: Random Forest (AUC-ROC: 0.8196)
```

### **Entrenar Modelo EspecÃ­fico**

```bash
# Random Forest
python run_pipeline.py --model-name random_forest

# Logistic Regression
python run_pipeline.py --model-name logistic_regression

# Decision Tree
python run_pipeline.py --model-name decision_tree
```

### **Opciones Avanzadas**

```bash
# Skip data preparation (usar datos ya procesados)
python run_pipeline.py --skip-data-prep --skip-feature-eng

# CV mÃ¡s rÃ¡pido (3 folds en lugar de 5)
python run_pipeline.py --cv-folds 3

# Sin generar grÃ¡ficos
python run_pipeline.py --no-plots

# Limpiar archivos generados
python run_pipeline.py clean
```

### **EjecuciÃ³n por Etapas**

```bash
# 1. Solo limpieza de datos
python -m fase2.dataset

# 2. Solo feature engineering
python -m fase2.features

# 3. Solo entrenamiento
python run_pipeline.py --skip-data-prep --skip-feature-eng
```

---

## ğŸš€ InstalaciÃ³n

```bash
# Clonar repositorio
git clone https://github.com/AlejandroDiaz10/MLOps
cd Fase2

# Crear entorno virtual
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate

# Instalar dependencias
pip install -r requirements.txt

# Instalar paquete en modo desarrollo
pip install -e .

# Verificar instalaciÃ³n
python -c "from fase2 import config; print('âœ… OK')"
```

---

## ğŸ“Š Archivos Generados

DespuÃ©s de ejecutar el pipeline:

**1. Modelos entrenados:**
```
models/
â”œâ”€â”€ random_forest_pipeline.pkl              # Pipeline completo
â”œâ”€â”€ random_forest_pipeline_metadata.json    # HiperparÃ¡metros y mÃ©tricas
â”œâ”€â”€ logistic_regression_pipeline.pkl
â””â”€â”€ decision_tree_pipeline.pkl
```

**2. Visualizaciones:**
```
reports/figures/
â”œâ”€â”€ confusion_matrix_random_forest_(pipeline).png
â”œâ”€â”€ roc_curve_random_forest_(pipeline).png
â””â”€â”€ model_comparison.png
```

**3. Datos procesados:**
```
data/processed/
â”œâ”€â”€ X_train.csv                 # Features de entrenamiento (scaled)
â”œâ”€â”€ X_test.csv                  # Features de prueba (scaled)
â”œâ”€â”€ y_train.csv                 # Labels de entrenamiento
â”œâ”€â”€ y_test.csv                  # Labels de prueba
â””â”€â”€ test_metrics_pipeline.json  # MÃ©tricas finales
```

---

## ğŸ› ï¸ Stack TecnolÃ³gico

**Core:**
- Python 3.12.1
- scikit-learn 1.3.0 (Pipeline, GridSearchCV)
- pandas 2.1.0
- numpy 1.24.3

**ConfiguraciÃ³n & CLI:**
- pydantic - ValidaciÃ³n de configuraciÃ³n
- typer - CLI moderna
- loguru - Logging estructurado

**VisualizaciÃ³n:**
- matplotlib 3.7.2
- seaborn 0.12.2

**MLOps (Etapa 4):**
- MLflow (pendiente) - Experiment tracking
- DVC (pendiente) - Data versioning

---

## ğŸ““ Notebooks

| Notebook | DescripciÃ³n |
|----------|-------------|
| `1.0-data-exploration` | AnÃ¡lisis exploratorio del dataset |
| `2.0-feature-engineering` | AnÃ¡lisis de features y outliers |
| `3.0-model-training` | ComparaciÃ³n de modelos |
| `4.0-sklearn-pipeline` | DemostraciÃ³n de sklearn Pipeline |

**Ejecutar:**
```bash
jupyter notebook notebooks/
```

---

## ğŸ“ Aprendizajes Clave

**1. Cookiecutter Data Science**
- Estructura estandarizada facilita mantenimiento
- SeparaciÃ³n datos/cÃ³digo mejora reproducibilidad
- OrganizaciÃ³n clara acelera onboarding

**2. ProgramaciÃ³n Orientada a Objetos**
- Method chaining mejora legibilidad
- Design patterns facilitan extensibilidad
- SeparaciÃ³n de responsabilidades reduce bugs

**3. sklearn Pipeline**
- Previene data leakage automÃ¡ticamente
- SerializaciÃ³n simplificada (un solo objeto)
- CÃ³digo listo para producciÃ³n desde el inicio

**4. Experiment Tracking (prÃ³ximo)**
- ComparaciÃ³n sistemÃ¡tica de modelos
- Versionamiento de artifacts
- AuditorÃ­a completa de experimentos

---

## ğŸ“„ Licencia

MIT License

---

**VersiÃ³n:** v3.0.0  
**Team 34** - Machine Learning Course  
**Octubre 2025**