# Fase 2: German Credit Risk Prediction

[![Python 3.12.1](https://img.shields.io/badge/python-3.12.1-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

Proyecto acadÃ©mico de Machine Learning para predecir riesgo crediticio utilizando el dataset German Credit, estructurado siguiendo mejores prÃ¡cticas de MLOps con Cookiecutter Data Science y programaciÃ³n orientada a objetos.

**Equipo:** Team 34  
**Curso:** Machine Learning  
**Fecha:** Octubre 2025

---

## ğŸ“‹ Tabla de Contenidos

- [Estado del Proyecto](#estado-del-proyecto)
- [DescripciÃ³n del Proyecto](#descripciÃ³n-del-proyecto)
- [Arquitectura](#arquitectura)
- [Estructura del Proyecto](#estructura-del-proyecto)
- [InstalaciÃ³n](#instalaciÃ³n)
- [Uso RÃ¡pido](#uso-rÃ¡pido)
- [Etapas Completadas](#etapas-completadas)
  - [Etapa 1: Estructura del Proyecto](#etapa-1-estructura-del-proyecto)
  - [Etapa 2: RefactorizaciÃ³n OOP](#etapa-2-refactorizaciÃ³n-oop)
  - [Etapa 3: sklearn Pipeline](#etapa-3-sklearn-pipeline-best-practices)
- [PrÃ³ximos Pasos](#prÃ³ximos-pasos-etapa-4)
- [GuÃ­as Detalladas](#guÃ­as-detalladas)
- [TecnologÃ­as](#tecnologÃ­as)

---

## ğŸ¯ Estado del Proyecto

| Etapa | Estado | DescripciÃ³n |
|-------|--------|-------------|
| **1. Estructura** | âœ… Completa | Cookiecutter Data Science + Setup inicial |
| **2. RefactorizaciÃ³n OOP** | âœ… Completa | CÃ³digo modular con clases y design patterns |
| **3. sklearn Pipeline** | âœ… Completa | Pipeline automatizado con best practices |
| **4. MLflow/DVC** | â³ Pendiente | Tracking de experimentos y versionamiento |

**VersiÃ³n actual:** `v3.0.0`

---

## ğŸ¯ DescripciÃ³n del Proyecto

Sistema de predicciÃ³n de riesgo crediticio que clasifica clientes como "buen crÃ©dito" (1) o "mal crÃ©dito" (0) utilizando el dataset **German Credit** de UCI.

**CaracterÃ­sticas implementadas:**
- âœ… Arquitectura orientada a objetos (OOP)
- âœ… Pipeline de ML completo y modular
- âœ… Sklearn Pipeline con GridSearchCV
- âœ… ConfiguraciÃ³n validada con Pydantic
- âœ… Method chaining para API limpia
- âœ… Exception handling robusto
- âœ… Visualizaciones automÃ¡ticas
- âœ… Backward compatibility

**MÃ©trica objetivo:** AUC-ROC â‰¥ 0.75

---

## ğŸ—ï¸ Arquitectura

### **Arquitectura en Capas**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CAPA 1: CLI / Scripts                      â”‚  â† run_pipeline.py, dataset.py
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  CAPA 2: Pipeline Orchestrator              â”‚  â† MLPipeline (facade)
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  CAPA 3: Core Business Logic (OOP)          â”‚  â† DataProcessor, FeatureEngineer, ModelTrainer, PipelineBuilder
â”‚         + sklearn Pipeline                  â”‚     
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  CAPA 4: Artifacts & Outputs                â”‚  â† models/, reports/, data/
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Flujo de Datos**
```mermaid
graph LR
    A[Raw Data] --> B[DataProcessor]
    B --> C[Cleaned Data]
    C --> D[FeatureEngineer]
    D --> E[Train/Test Split]
    E --> F[sklearn Pipeline]
    F --> G[Trained Model]
    G --> H[Predictions]
    H --> I[Metrics & Plots]
```

### **Componentes Principales**

| Componente | Responsabilidad | PatrÃ³n |
|------------|----------------|--------|
| `DataProcessor` | Limpieza y validaciÃ³n | Method Chaining |
| `FeatureEngineer` | Feature engineering | Method Chaining |
| `ModelTrainer` | Entrenamiento | Template Method |
| `ModelEvaluator` | EvaluaciÃ³n | - |
| `ModelFactory` | CreaciÃ³n de modelos | Factory Pattern |
| `PipelineBuilder` | ConstrucciÃ³n de sklearn Pipeline | Builder Pattern |
| `MLPipeline` | OrquestaciÃ³n | Facade Pattern |

---

## ğŸ“ Estructura del Proyecto
```
Fase2/
â”œâ”€â”€ README.md                    # Este archivo
â”œâ”€â”€ requirements.txt             # Dependencias
â”œâ”€â”€ pyproject.toml              # ConfiguraciÃ³n del proyecto
â”œâ”€â”€ run_pipeline.py             # ğŸ¯ Script principal (EMPEZAR AQUÃ)
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Datos originales (inmutables)
â”‚   â”‚   â””â”€â”€ german_credit_modified.csv
â”‚   â”œâ”€â”€ interim/                # Datos limpiados
â”‚   â”‚   â””â”€â”€ german_credit_cleaned.csv
â”‚   â”œâ”€â”€ processed/              # Datos finales para ML
â”‚   â”‚   â”œâ”€â”€ X_train.csv
â”‚   â”‚   â”œâ”€â”€ X_test.csv
â”‚   â”‚   â”œâ”€â”€ y_train.csv
â”‚   â”‚   â””â”€â”€ y_test.csv
â”‚   â””â”€â”€ external/
â”‚
â”œâ”€â”€ models/                     # Modelos entrenados (.pkl)
â”‚   â”œâ”€â”€ random_forest_pipeline.pkl
â”‚   â”œâ”€â”€ random_forest_pipeline_metadata.json
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ notebooks/                  # AnÃ¡lisis interactivo
â”‚   â”œâ”€â”€ 1.0-t34-data-exploration.ipynb
â”‚   â”œâ”€â”€ 2.0-t34-feature-engineering.ipynb
â”‚   â”œâ”€â”€ 3.0-t34-model-training.ipynb
â”‚   â””â”€â”€ 4.0-t34-sklearn-pipeline-best-practices.ipynb  
â”‚
â”œâ”€â”€ reports/
â”‚   â””â”€â”€ figures/                # Visualizaciones
â”‚       â”œâ”€â”€ confusion_matrix_*.png
â”‚       â”œâ”€â”€ roc_curve_*.png
â”‚       â””â”€â”€ model_comparison.png
â”‚
â”œâ”€â”€ docs/                       # DocumentaciÃ³n adicional
â”‚   â””â”€â”€ SKLEARN_PIPELINE_GUIDE.md
â”‚
â””â”€â”€ fase2/                      # ğŸ“¦ CÃ³digo fuente (paquete Python)
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ config.py               # ConfiguraciÃ³n con Pydantic
    â”œâ”€â”€ exceptions.py           # Custom exceptions
    â”œâ”€â”€ pipeline.py             # MLPipeline orchestrator
    â”œâ”€â”€ plots.py                # Funciones de visualizaciÃ³n
    â”œâ”€â”€ transformers.py         # Custom sklearn transformers
    â”œâ”€â”€ pipeline_builder.py     # ConstrucciÃ³n de sklearn Pipeline
    â”œâ”€â”€ demo_pipeline.py        # Script de demostraciÃ³n
    â”‚
    â”œâ”€â”€ core/                   # LÃ³gica de negocio (OOP)
    â”‚   â”œâ”€â”€ data_processor.py
    â”‚   â”œâ”€â”€ feature_engineer.py
    â”‚   â”œâ”€â”€ model_factory.py
    â”‚   â”œâ”€â”€ trainer.py
    â”‚   â””â”€â”€ evaluator.py
    â”‚
    â”œâ”€â”€ utils/                  # Utilidades
    â”‚   â”œâ”€â”€ logger.py
    â”‚   â””â”€â”€ validators.py
    â”‚
    â”œâ”€â”€ dataset.py              # CLI para limpieza
    â”œâ”€â”€ features.py             # CLI para features
    â””â”€â”€ modeling/
        â”œâ”€â”€ train.py            # CLI para entrenamiento
        â””â”€â”€ predict.py          # CLI para predicciÃ³n
```

---

## ğŸš€ InstalaciÃ³n

### **1. Prerrequisitos**

- Python 3.12.1+
- pip
- virtualenv (recomendado)
- Git

### **2. Setup Completo**
```bash
# Clonar repositorio
git clone https://github.com/AlejandroDiaz10/MLOps
cd Fase2

# Crear entorno virtual
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate

# Instalar dependencias
pip install -r requirements.txt

# Instalar paquete en modo desarrollo
pip install -e .

# Verificar instalaciÃ³n
python -c "from fase2 import config; print('âœ… Installation successful')"
```

### **3. Verificar Estructura**
```bash
# Ver estructura de directorios
tree -L 2  # Linux/Mac
# o
ls -R      # Alternativa

# Verificar que existen los datos raw
ls data/raw/german_credit_modified.csv
```

---

## âš¡ Uso RÃ¡pido

### **OpciÃ³n 1: Pipeline Completo con sklearn (Recomendado)**
```bash
# Ejecutar TODO el pipeline de ML
python run_pipeline.py sklearn
```

**Esto ejecuta automÃ¡ticamente:**
1. âœ… Data preparation â†’ `data/interim/german_credit_cleaned.csv`
2. âœ… Feature engineering â†’ `data/processed/X_train.csv`, etc.
3. âœ… sklearn Pipeline training con GridSearchCV
4. âœ… EvaluaciÃ³n en test set
5. âœ… GeneraciÃ³n de visualizaciones

**Archivos generados:**
```
models/
â””â”€â”€ random_forest_pipeline.pkl              # Pipeline completo
â””â”€â”€ random_forest_pipeline_metadata.json    # Metadata

data/processed/
â””â”€â”€ test_predictions_pipeline.csv
â””â”€â”€ test_metrics_pipeline.json

reports/figures/
â””â”€â”€ confusion_matrix_random_forest_(pipeline).png
â””â”€â”€ roc_curve_random_forest_(pipeline).png
```

### **OpciÃ³n 2: Demo RÃ¡pido**
```bash
# DemostraciÃ³n del sklearn Pipeline 
python -m fase2.demo_pipeline
```

### **OpciÃ³n 3: Paso por Paso**
```bash
# 1. Limpiar datos
python -m fase2.dataset

# 2. Feature engineering
python -m fase2.features

# 3. Entrenar modelo
python run_pipeline.py sklearn

# 4. Diferentes modelos
python run_pipeline.py sklearn --model-name logistic_regression
python run_pipeline.py sklearn --model-name decision_tree
```

---

## âœ… Etapas Completadas

### **Etapa 1: Estructura del Proyecto**

**Objetivo:** Establecer estructura estandarizada del proyecto.

**Implementado:**
- âœ… Cookiecutter Data Science structure
- âœ… ConfiguraciÃ³n con Pydantic (`config.py`)
- âœ… Setup de logging (`utils/logger.py`)
- âœ… Git repository inicializado

**DocumentaciÃ³n:** Ver estructura en [Estructura del Proyecto](#estructura-del-proyecto)

---

### **Etapa 2: RefactorizaciÃ³n OOP**

**Objetivo:** Organizar cÃ³digo en mÃ³dulos con responsabilidades claras usando OOP.

#### **Clases Implementadas**

**1. DataProcessor (`core/data_processor.py`)**
- Carga de datos raw
- TraducciÃ³n de columnas
- Limpieza de whitespace
- ConversiÃ³n a tipos numÃ©ricos
- ValidaciÃ³n de target
- Manejo de missing values
- ValidaciÃ³n de rangos categÃ³ricos
- RemociÃ³n de duplicados

**Uso:**
```python
from fase2.core.data_processor import DataProcessor

processor = DataProcessor()
df_clean = processor \
    .load_raw_data() \
    .translate_columns() \
    .clean_whitespace() \
    .convert_to_numeric() \
    .validate_target() \
    .handle_missing_values() \
    .validate_categorical_ranges() \
    .remove_duplicates() \
    .get_data()
```

**2. FeatureEngineer (`core/feature_engineer.py`)**
- DetecciÃ³n de outliers
- SeparaciÃ³n de features/target
- Train-test split
- Feature scaling
- Guardado de artefactos

**Uso:**
```python
from fase2.core.feature_engineer import FeatureEngineer

engineer = FeatureEngineer()
engineer \
    .load_data() \
    .detect_outliers() \
    .split_target() \
    .train_test_split() \
    .scale_features() \
    .save_all()
```

**3. ModelTrainer (`core/trainer.py`)**
- Entrenamiento con GridSearchCV
- Cross-validation
- BÃºsqueda de hiperparÃ¡metros
- Guardado de modelos

**4. ModelEvaluator (`core/evaluator.py`)**
- PredicciÃ³n en test set
- CÃ¡lculo de mÃ©tricas
- Classification report
- Guardado de resultados

**5. ModelFactory (`core/model_factory.py`)**
- Factory Pattern para crear modelos
- Grids de hiperparÃ¡metros predefinidos
- Modelos soportados: Random Forest, Logistic Regression, Decision Tree

**6. MLPipeline (`pipeline.py`)**
- Orquestador maestro
- Ejecuta workflow completo
- ComparaciÃ³n de mÃºltiples modelos

#### **Design Patterns Aplicados**

| Pattern | DÃ³nde | Para QuÃ© |
|---------|-------|----------|
| **Factory** | `ModelFactory` | CreaciÃ³n de modelos |
| **Builder** | `PipelineBuilder` | ConstrucciÃ³n de pipelines |
| **Template Method** | `MLPipeline` | Workflow estÃ¡ndar |
| **Facade** | `MLPipeline` | Interfaz simplificada |
| **Method Chaining** | Todas las clases core | API fluida |

#### **Principios SOLID**

- âœ… **Single Responsibility:** Cada clase tiene una responsabilidad
- âœ… **Open/Closed:** Extensible vÃ­a herencia/composiciÃ³n
- âœ… **Dependency Inversion:** Config inyectable

---

### **Etapa 3: sklearn Pipeline (Best Practices)**

**Objetivo:** Implementar pipeline de scikit-learn que automatice preprocesamiento, entrenamiento y evaluaciÃ³n.

#### **Â¿Por quÃ© sklearn Pipeline?**

**Problemas sin Pipeline:**
- âŒ Data leakage (fit en todo el dataset)
- âŒ MÃºltiples objetos a serializar
- âŒ FÃ¡cil olvidar preprocessing en producciÃ³n
- âŒ DifÃ­cil reproducir experimentos

**SoluciÃ³n con Pipeline:**
- âœ… Un solo objeto `.pkl` serializable
- âœ… Preprocessing automÃ¡tico en train y test
- âœ… No data leakage (fit solo en train)
- âœ… GridSearchCV sobre todo el pipeline
- âœ… Listo para producciÃ³n

#### **Componentes Implementados**

**1. Custom Transformers (`transformers.py`)**

Transformers compatibles con sklearn que siguen la API `fit/transform`:
```python
class OutlierRemover(BaseEstimator, TransformerMixin):
    """Clip outliers usando IQR method."""
    def fit(self, X, y=None):
        # Aprender bounds del train set
        return self
    
    def transform(self, X):
        # Aplicar clipping
        return X_clipped
```

**Transformers disponibles:**
- `OutlierRemover` - Clip outliers con IQR
- `TypeConverter` - ConversiÃ³n a tipos numÃ©ricos
- `CategoricalValidator` - ValidaciÃ³n de categorÃ­as
- `DataFrameSelector` - SelecciÃ³n de columnas

**2. PipelineBuilder (`pipeline_builder.py`)**

Constructor de pipelines sklearn:
```python
from fase2.pipeline_builder import PipelineBuilder

builder = PipelineBuilder()

# Pipeline simple
pipeline = builder.build_pipeline('random_forest')

# Pipeline con GridSearch
grid_pipeline = builder.build_grid_search_pipeline(
    model_name='random_forest',
    cv_folds=5
)
```

**Estructura del Pipeline:**
```
sklearn.pipeline.Pipeline
â”œâ”€â”€ imputer (SimpleImputer)        # ImputaciÃ³n de NaN
â”œâ”€â”€ scaler (StandardScaler)        # Escalado de features
â””â”€â”€ model (RandomForestClassifier) # Modelo ML
```

#### **Flujo de Trabajo con sklearn Pipeline**
```
1. Data Cleaning (dataset.py)
   â””â”€â”€ Limpieza manual â†’ interim/

2. Feature Engineering (features.py)
   â””â”€â”€ Outliers, train-test split â†’ processed/

3. sklearn Pipeline (pipeline_builder.py)
   â”œâ”€â”€ Imputation (aprende de train)
   â”œâ”€â”€ Scaling (aprende de train)
   â””â”€â”€ Model training
```

#### **Uso del sklearn Pipeline**

**MÃ©todo 1: CLI (Recomendado)**
```bash
python run_pipeline.py sklearn
```

**MÃ©todo 2: ProgramÃ¡tico**
```python
from fase2.pipeline_builder import PipelineBuilder

builder = PipelineBuilder()
pipeline = builder.build_grid_search_pipeline('random_forest')
pipeline.fit(X_train, y_train)

# Guardar
import joblib
joblib.dump(pipeline.best_estimator_, 'model.pkl')

# Cargar y usar
loaded_pipeline = joblib.load('model.pkl')
predictions = loaded_pipeline.predict(X_new)
```

**MÃ©todo 3: Notebook Interactivo**
```bash
jupyter notebook notebooks/4.0-t34-sklearn-pipeline-best-practices.ipynb
```

#### **Best Practices Implementadas**

| Practice | ImplementaciÃ³n | Beneficio |
|----------|----------------|-----------|
| **No Data Leakage** | `fit()` solo en train | Resultados vÃ¡lidos |
| **Single Object** | Pipeline completo en .pkl | FÃ¡cil deployment |
| **Grid Search** | Sobre todo el pipeline | Optimal hyperparams |
| **Reproducibilidad** | `random_state=42` everywhere | Resultados consistentes |
| **DocumentaciÃ³n** | Docstrings + Type hints | CÃ³digo mantenible |

#### **Archivos Clave de la Etapa 3**
```
fase2/
â”œâ”€â”€ transformers.py          # Custom sklearn transformers
â”œâ”€â”€ pipeline_builder.py      # Constructor de pipelines
â””â”€â”€ demo_pipeline.py         # Script de demostraciÃ³n

notebooks/
â””â”€â”€ 4.0-t34-sklearn-pipeline-best-practices.ipynb

docs/
â””â”€â”€ SKLEARN_PIPELINE_GUIDE.md  # GuÃ­a completa
```

---

## ğŸ”œ PrÃ³ximos Pasos (Etapa 4)

### **Objetivos de la Etapa 4**

Implementar tracking de experimentos y versionamiento de datos/modelos.

#### **Tareas Pendientes**

**1. MLflow - Tracking de Experimentos**
- [ ] Setup de MLflow server
- [ ] Logging automÃ¡tico de parÃ¡metros
- [ ] Logging de mÃ©tricas (AUC, accuracy, etc.)
- [ ] Registro de artifacts (modelos, plots)
- [ ] ComparaciÃ³n de runs en UI
- [ ] Registro de modelos en Model Registry

**2. DVC - Versionamiento de Datos**
- [ ] Inicializar DVC en el proyecto
- [ ] Configurar remote storage
- [ ] Versionar `data/raw/`
- [ ] Versionar `data/processed/`
- [ ] Versionar `models/`
- [ ] Pipeline de DVC

**3. VisualizaciÃ³n de Resultados**
- [ ] Dashboard de MLflow
- [ ] ComparaciÃ³n de experimentos
- [ ] GrÃ¡ficos de convergencia
- [ ] AnÃ¡lisis de hiperparÃ¡metros

**4. GestiÃ³n de Modelos**
- [ ] Model Registry con versiones
- [ ] Metadata completo por versiÃ³n
- [ ] TransiciÃ³n de stages (Staging â†’ Production)
- [ ] Rollback capability

#### **Recursos para Etapa 4**

**DocumentaciÃ³n:**
- [MLflow Tracking](https://mlflow.org/docs/latest/tracking.html)
- [MLflow Models](https://mlflow.org/docs/latest/models.html)
- [DVC Get Started](https://dvc.org/doc/start)
- [DVC with Google Drive](https://dvc.org/doc/user-guide/data-management/remote-storage/google-drive)

---

### **Notebooks Disponibles**

1. **`1.0-t34-data-exploration.ipynb`** - EDA del dataset
2. **`2.0-t34-feature-engineering.ipynb`** - ExploraciÃ³n de features
3. **`3.0-t34-model-training.ipynb`** - Entrenamiento de modelos
4. **`4.0-t34-sklearn-pipeline-best-practices.ipynb`** - Demo de sklearn Pipeline

### **Scripts Ãštiles**

| Script | PropÃ³sito | Comando |
|--------|-----------|---------|
| `run_pipeline.py` | Pipeline completo | `python run_pipeline.py sklearn` |
| `fase2/demo_pipeline.py` | Demo rÃ¡pido | `python -m fase2.demo_pipeline` |
| `fase2/dataset.py` | Solo limpieza | `python -m fase2.dataset` |
| `fase2/features.py` | Solo features | `python -m fase2.features` |

---

## ğŸ› ï¸ TecnologÃ­as

**Core:**
- Python 3.12.1
- pandas 2.1.0
- numpy 1.24.3
- scikit-learn 1.3.0

**ConfiguraciÃ³n y ValidaciÃ³n:**
- pydantic - ValidaciÃ³n de configuraciÃ³n
- loguru - Logging estructurado
- typer - CLI moderna

**VisualizaciÃ³n:**
- matplotlib 3.7.2
- seaborn 0.12.2

**ML Pipeline:**
- scikit-learn Pipeline
- GridSearchCV
- Custom Transformers

**Desarrollo:**
- Cookiecutter Data Science
- Git
- Jupyter
- joblib

**Etapa 4:**
- MLflow - Experiment tracking
- DVC - Data versioning
- (Opcional) GitHub Actions - CI/CD

---

## ğŸ› Troubleshooting

### **Problema: Datos no encontrados**
```bash
# Verificar estructura
ls data/raw/
ls data/processed/

# Si faltan, ejecutar:
python -m fase2.dataset
python -m fase2.features
```

### **Problema: MÃ³dulo no encontrado**
```bash
# Reinstalar paquete
pip install -e .
```

### **Problema: GridSearchCV muy lento**
Para acelerar durante desarrollo, edita `fase2/core/model_factory.py`:
```python
# Grid reducido para testing
'random_forest': {
    'n_estimators': [100],      # Solo 1 valor
    'max_depth': [20],          # Solo 1 valor
    'min_samples_split': [2]    # Solo 1 valor
}
```

---

## ğŸ“„ Licencia

MIT License - ver [LICENSE](LICENSE) para detalles.

---

**Ãšltima actualizaciÃ³n:** Octubre 2025  
**VersiÃ³n:** v3.0.0  