# Fase 2: German Credit Risk Prediction

[![Python 3.12.1](https://img.shields.io/badge/python-3.12.1-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

Proyecto acadÃ©mico de Machine Learning para predecir riesgo crediticio utilizando el dataset German Credit, estructurado siguiendo mejores prÃ¡cticas de MLOps con Cookiecutter Data Science y programaciÃ³n orientada a objetos.

**Equipo:** Team 34  
**Curso:** Machine Learning  
**Fecha:** Octubre 2025

---

## ğŸ“‹ Tabla de Contenidos

- [DescripciÃ³n del Proyecto](#descripciÃ³n-del-proyecto)
- [Arquitectura](#arquitectura)
- [Estructura del Proyecto](#estructura-del-proyecto)
- [InstalaciÃ³n](#instalaciÃ³n)
- [Uso](#uso)
  - [OpciÃ³n 1: Pipeline Completo](#opciÃ³n-1-pipeline-completo-recomendado)
  - [OpciÃ³n 2: Paso por Paso](#opciÃ³n-2-paso-por-paso)
  - [OpciÃ³n 3: Comparar Modelos](#opciÃ³n-3-comparar-mÃºltiples-modelos)
  - [OpciÃ³n 4: Uso ProgramÃ¡tico](#opciÃ³n-4-uso-programÃ¡tico)
- [Visualizaciones](#visualizaciones)
- [Notebooks Interactivos](#notebooks-interactivos)
- [TecnologÃ­as](#tecnologÃ­as)
- [Aprendizajes Clave](#aprendizajes-clave)

---

## ğŸ¯ DescripciÃ³n del Proyecto

Este proyecto implementa un sistema de predicciÃ³n de riesgo crediticio utilizando el dataset **German Credit**. El objetivo es clasificar clientes como "buen crÃ©dito" (1) o "mal crÃ©dito" (0) basÃ¡ndose en caracterÃ­sticas demogrÃ¡ficas y financieras.

**CaracterÃ­sticas principales:**
- âœ… Arquitectura orientada a objetos (OOP)
- âœ… Pipeline de ML completo y modular
- âœ… Estructura estandarizada con Cookiecutter Data Science
- âœ… ConfiguraciÃ³n validada con Pydantic
- âœ… Method chaining para API limpia
- âœ… Exception handling robusto
- âœ… Visualizaciones automÃ¡ticas
- âœ… CÃ³digo reutilizable y mantenible
- âœ… Backward compatibility con cÃ³digo funcional

**MÃ©trica objetivo:** AUC-ROC â‰¥ 0.75

---

## ğŸ—ï¸ Arquitectura

El proyecto implementa una **arquitectura en capas** con separaciÃ³n de responsabilidades:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CAPA 1: CLI / Scripts                      â”‚  â† Interfaz de usuario
â”‚  (run_pipeline.py, dataset.py, etc.)        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  CAPA 2: Pipeline Orchestrator              â”‚  â† CoordinaciÃ³n
â”‚  (MLPipeline)                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  CAPA 3: Core Business Logic (OOP)          â”‚  â† LÃ³gica principal
â”‚  (DataProcessor, FeatureEngineer,           â”‚
â”‚   ModelTrainer, ModelEvaluator)             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  CAPA 4: Outputs & Artifacts                â”‚  â† Resultados
â”‚  (models/, reports/, data/processed/)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Clases Principales**

| Clase | Responsabilidad | PatrÃ³n |
|-------|----------------|--------|
| `DataProcessor` | Limpieza y validaciÃ³n de datos | Method Chaining |
| `FeatureEngineer` | IngenierÃ­a de caracterÃ­sticas | Method Chaining |
| `ModelTrainer` | Entrenamiento con GridSearchCV | Template Method |
| `ModelEvaluator` | EvaluaciÃ³n y predicciÃ³n | - |
| `ModelFactory` | CreaciÃ³n de modelos | Factory Pattern |
| `MLPipeline` | OrquestaciÃ³n del workflow | Facade Pattern |

### **Backward Compatibility**

El proyecto mantiene **dos APIs simultÃ¡neas** para mÃ¡xima flexibilidad:

**API Funcional (Legacy):**
```python
from fase2.config import RAW_DATA_DIR, TARGET_COL
from fase2.dataset import load_raw_data
```

**API Orientada a Objetos (Recomendada):**
```python
from fase2.config import config
from fase2.core.data_processor import DataProcessor
```

Ambas APIs coexisten sin conflictos, permitiendo:
- âœ… Notebooks antiguos siguen funcionando
- âœ… Nuevo cÃ³digo usa OOP
- âœ… MigraciÃ³n gradual sin romper funcionalidad

---

## ğŸ“ Estructura del Proyecto
```
Fase2/
â”œâ”€â”€ LICENSE
â”œâ”€â”€ README.md
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ run_pipeline.py          # ğŸ†• Script principal
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                 # Datos originales (inmutables)
â”‚   â”œâ”€â”€ interim/             # Datos limpiados
â”‚   â”œâ”€â”€ processed/           # Datos finales para modelado
â”‚   â””â”€â”€ external/
â”‚
â”œâ”€â”€ models/                  # Modelos (.pkl) y metadata (.json)
â”‚
â”œâ”€â”€ notebooks/               # AnÃ¡lisis exploratorio
â”‚   â”œâ”€â”€ 1.0-t34-data-exploration.ipynb
â”‚   â”œâ”€â”€ 2.0-t34-feature-engineering.ipynb
â”‚   â””â”€â”€ 3.0-t34-model-training.ipynb
â”‚
â”œâ”€â”€ reports/
â”‚   â””â”€â”€ figures/             # Visualizaciones generadas
â”‚
â””â”€â”€ fase2/                   # ğŸ†• CÃ³digo fuente (OOP)
    â”œâ”€â”€ config.py            # ConfiguraciÃ³n con Pydantic
    â”œâ”€â”€ exceptions.py        # Custom exceptions
    â”œâ”€â”€ pipeline.py          # MLPipeline orchestrator
    â”œâ”€â”€ plots.py             # Funciones de visualizaciÃ³n
    â”‚
    â”œâ”€â”€ core/                # LÃ³gica de negocio
    â”‚   â”œâ”€â”€ data_processor.py
    â”‚   â”œâ”€â”€ feature_engineer.py
    â”‚   â”œâ”€â”€ model_factory.py
    â”‚   â”œâ”€â”€ trainer.py
    â”‚   â””â”€â”€ evaluator.py
    â”‚
    â”œâ”€â”€ utils/               # Utilidades
    â”‚   â”œâ”€â”€ logger.py
    â”‚   â””â”€â”€ validators.py
    â”‚
    â”œâ”€â”€ dataset.py           # CLI para limpieza (wrapper)
    â”œâ”€â”€ features.py          # CLI para features (wrapper)
    â””â”€â”€ modeling/
        â”œâ”€â”€ train.py         # CLI para entrenamiento (wrapper)
        â””â”€â”€ predict.py       # CLI para predicciÃ³n (wrapper)
```

---

## ğŸš€ InstalaciÃ³n

### Prerrequisitos

- Python 3.12.1+
- pip
- virtualenv (recomendado)

### Pasos
```bash
# 1. Clonar repositorio
git clone https://github.com/AlejandroDiaz10/MLOps
cd Fase2

# 2. Crear entorno virtual
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate

# 3. Instalar dependencias
pip install -r requirements.txt

# 4. Instalar paquete en modo desarrollo
pip install -e .

# 5. Verificar instalaciÃ³n
python -c "from fase2 import config; print('âœ“ Installation successful')"
```

---

## ğŸ’» Uso

### **OpciÃ³n 1: Pipeline Completo** (Recomendado) ğŸš€

Ejecuta el workflow completo con un comando:
```bash
# Pipeline completo: limpieza â†’ features â†’ entrenamiento â†’ evaluaciÃ³n â†’ plots
python run_pipeline.py full
```

**Con opciones:**
```bash
# Modelo especÃ­fico
python run_pipeline.py full --model-name logistic_regression

# Saltar pasos ya completados
python run_pipeline.py full --skip-data-prep --skip-feature-eng
```

**Output generado:**
- `data/interim/german_credit_cleaned.csv`
- `data/processed/X_train.csv`, `X_test.csv`, `y_train.csv`, `y_test.csv`
- `models/random_forest.pkl` + `random_forest_metadata.json`
- `data/processed/test_predictions.csv`, `test_metrics.json`
- `reports/figures/confusion_matrix_random_forest.png`
- `reports/figures/roc_curve_random_forest.png`
- `reports/figures/feature_importance_random_forest.png`

---

### **OpciÃ³n 2: Paso por Paso**

Ejecuta cada etapa individualmente para debugging:
```bash
# 1. Limpieza de datos
python -m fase2.dataset
# Output: data/interim/german_credit_cleaned.csv

# 2. Feature Engineering
python -m fase2.features
# Output: data/processed/X_train.csv, X_test.csv, y_train.csv, y_test.csv

# 3. Entrenamiento
python -m fase2.modeling.train --model-name random_forest
# Output: models/random_forest.pkl + metadata

# 4. EvaluaciÃ³n
python -m fase2.modeling.predict --model-path models/random_forest.pkl
# Output: test_predictions.csv, test_metrics.json
```

---

### **OpciÃ³n 3: Comparar MÃºltiples Modelos**

Entrena y compara todos los modelos automÃ¡ticamente:
```bash
# Entrenar y comparar: random_forest, logistic_regression, decision_tree
python run_pipeline.py compare
```

**Visualizaciones generadas:**

**Por cada modelo:**
- `confusion_matrix_<model>.png`
- `roc_curve_<model>.png`
- `feature_importance_<model>.png`

**Comparaciones generales:**
- `target_distribution.png` - DistribuciÃ³n de clases
- `model_comparison.png` - MÃ©tricas lado a lado
- `roc_curves_comparison.png` - Todas las ROC juntas
- `cv_scores_comparison.png` - Cross-validation scores

**Comandos Ãºtiles:**
```bash
# Ver modelos disponibles
python run_pipeline.py models

# Comparar con datos ya procesados
python run_pipeline.py compare --skip-data-prep --skip-feature-eng
```

---

### **OpciÃ³n 4: Uso ProgramÃ¡tico**

#### **A) API de Alto Nivel (MLPipeline)**
```python
from fase2.pipeline import MLPipeline

# Pipeline completo
pipeline = MLPipeline()
results = pipeline.run_full_pipeline(model_name='random_forest')

# Acceder a resultados
print(f"Accuracy: {results['metrics']['accuracy']:.4f}")
print(f"AUC-ROC: {results['metrics']['auc_roc']:.4f}")
print(f"Model: {results['model_path']}")

# Ejecutar paso por paso
pipeline.run_data_preparation()
pipeline.run_feature_engineering()
pipeline.run_training('logistic_regression')
metrics = pipeline.run_evaluation()
figures = pipeline.run_visualization()

# Comparar modelos
results = pipeline.run_multiple_models(
    model_names=['random_forest', 'logistic_regression'],
    generate_plots=True
)
```

#### **B) API de Bajo Nivel (Clases Individuales)**
```python
from fase2.core.data_processor import DataProcessor
from fase2.core.feature_engineer import FeatureEngineer
from fase2.core.trainer import ModelTrainer
from fase2.core.evaluator import ModelEvaluator

# 1. Procesamiento de datos con method chaining
processor = DataProcessor()
df_clean = processor \
    .load_raw_data() \
    .translate_columns() \
    .clean_whitespace() \
    .convert_to_numeric() \
    .validate_target() \
    .handle_missing_values() \
    .validate_categorical_ranges() \
    .remove_duplicates() \
    .get_data()

# 2. Feature engineering
engineer = FeatureEngineer()
paths = engineer \
    .load_data() \
    .detect_outliers() \
    .split_target() \
    .train_test_split() \
    .scale_features() \
    .save_all()

X_train, X_test, y_train, y_test = engineer.get_train_test_split()

# 3. Entrenamiento
trainer = ModelTrainer()
model_path = trainer \
    .load_training_data() \
    .train('random_forest') \
    .evaluate() \
    .save()

# 4. EvaluaciÃ³n
evaluator = ModelEvaluator()
metrics = evaluator \
    .load_model(model_path) \
    .load_test_data() \
    .predict() \
    .evaluate() \
    .save_predictions() \
    .save_metrics() \
    .get_metrics()

evaluator.print_classification_report()
```

#### **C) API Funcional (Legacy - Notebooks)**
```python
# Importaciones legacy (siguen funcionando)
from fase2.config import RAW_DATA_DIR, TARGET_COL
from fase2.dataset import load_raw_data, translate_columns
from fase2.features import scale_features

# Usar funciones directamente (como antes)
df = load_raw_data()
df = translate_columns(df)
# ... etc
```

---

## ğŸ“Š Visualizaciones

El pipeline genera automÃ¡ticamente visualizaciones profesionales en `reports/figures/`:

### **Visualizaciones por Modelo**

| Plot | DescripciÃ³n | Archivo |
|------|-------------|---------|
| Confusion Matrix | Matriz de confusiÃ³n con porcentajes | `confusion_matrix_<model>.png` |
| ROC Curve | Curva ROC con AUC score | `roc_curve_<model>.png` |
| Feature Importance | Top 15 features mÃ¡s importantes | `feature_importance_<model>.png` |

### **Visualizaciones Comparativas**

| Plot | DescripciÃ³n | Archivo |
|------|-------------|---------|
| Target Distribution | DistribuciÃ³n de clases (balanceo) | `target_distribution.png` |
| Model Comparison | MÃ©tricas lado a lado (bar chart) | `model_comparison.png` |
| ROC Comparison | Todas las curvas ROC juntas | `roc_curves_comparison.png` |
| CV Scores | Cross-validation performance | `cv_scores_comparison.png` |

**CaracterÃ­sticas:**
- âœ… ResoluciÃ³n 300 DPI (publicaciÃ³n)
- âœ… Colores profesionales (viridis, seaborn)
- âœ… Anotaciones con valores numÃ©ricos
- âœ… Threshold lines para AUC â‰¥ 0.75
- âœ… Formato PNG optimizado

---

## ğŸ““ Notebooks Interactivos

Los notebooks en `notebooks/` demuestran anÃ¡lisis exploratorio:

1. **`1.0-t34-data-exploration.ipynb`**
   - AnÃ¡lisis exploratorio del dataset
   - EstadÃ­sticas descriptivas
   - Distribuciones de features

2. **`2.0-t34-feature-engineering.ipynb`**
   - ExploraciÃ³n de ingenierÃ­a de features
   - DetecciÃ³n de outliers
   - AnÃ¡lisis de correlaciones

3. **`3.0-t34-model-training.ipynb`**
   - Entrenamiento de modelos
   - ComparaciÃ³n de performance
   - AnÃ¡lisis de resultados

### **Setup para Notebooks**
```python
# Habilitar autoreload (recarga automÃ¡tica de mÃ³dulos)
%load_ext autoreload
%autoreload 2

# Importar API OOP (recomendado)
from fase2.pipeline import MLPipeline
from fase2.core.data_processor import DataProcessor

# Usar
pipeline = MLPipeline()
processor = DataProcessor()
df = processor.load_raw_data().translate_columns().get_data()

# API funcional tambiÃ©n disponible
from fase2.config import INTERIM_DATA_DIR
import pandas as pd
df = pd.read_csv(INTERIM_DATA_DIR / 'german_credit_cleaned.csv')
```

---

## ğŸ› ï¸ TecnologÃ­as

**Core:**
- Python 3.12.1
- pandas 2.1.0 - ManipulaciÃ³n de datos
- numpy 1.24.3 - CÃ¡lculos numÃ©ricos
- scikit-learn 1.3.0 - Modelos ML

**ValidaciÃ³n y ConfiguraciÃ³n:**
- pydantic - ValidaciÃ³n de esquemas
- loguru - Logging estructurado
- typer - CLI moderna

**VisualizaciÃ³n:**
- matplotlib 3.7.2
- seaborn 0.12.2

**Desarrollo:**
- Cookiecutter Data Science - Estructura
- Git - Control de versiones
- Jupyter - AnÃ¡lisis interactivo
- joblib - SerializaciÃ³n

---

## ğŸ“ Aprendizajes Clave

Este proyecto demuestra implementaciÃ³n profesional de:

### **1. ProgramaciÃ³n Orientada a Objetos**
- âœ… Clases con responsabilidades Ãºnicas (SRP)
- âœ… EncapsulaciÃ³n de estado y comportamiento
- âœ… Method chaining para API fluida
- âœ… Type hints completos

### **2. Design Patterns**
- âœ… **Factory Pattern** - `ModelFactory` para creaciÃ³n de modelos
- âœ… **Template Method** - `MLPipeline` para workflow estÃ¡ndar
- âœ… **Facade Pattern** - Interfaz simplificada para sistema complejo

### **3. Software Engineering Best Practices**
- âœ… **Separation of Concerns** - Arquitectura en capas
- âœ… **DRY Principle** - CÃ³digo reutilizable
- âœ… **Configuration as Code** - Pydantic para validaciÃ³n
- âœ… **Error Handling** - Custom exceptions descriptivas
- âœ… **Backward Compatibility** - API dual (funcional + OOP)

### **4. MLOps Practices**
- âœ… Pipeline reproducible
- âœ… Versionamiento de modelos (metadata JSON)
- âœ… Logging estructurado
- âœ… ConfiguraciÃ³n centralizada
- âœ… Visualizaciones automÃ¡ticas

---

## ğŸ“„ Licencia

MIT License - ver [LICENSE](LICENSE) para detalles.

---

## ğŸ“š Referencias

- **Dataset:** [UCI Machine Learning Repository - German Credit](https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data))
- **Template:** [Cookiecutter Data Science](https://drivendata.github.io/cookiecutter-data-science/)
- **DocumentaciÃ³n Scikit-learn:** [scikit-learn.org](https://scikit-learn.org/)


---

**Proyecto acadÃ©mico con fines educativos - Octubre 2025**